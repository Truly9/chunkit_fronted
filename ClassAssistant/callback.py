from dashscope import Application
from http import HTTPStatus
import os
import json
from multiRAG import MultiRAG

# ä»Pathæ–‡ä»¶é‡Œé¢å¼•å…¥çŸ¥è¯†åº“æ–‡ä»¶åœ°å€,ç´¢å¼•æ–‡ä»¶çš„åœ°å€
from Utils.Path import (
    PAPER_DOCS_DIR, CAMPUS_DOCS_DIR, FITNESS_DOCS_DIR, PSYCHOLOGY_DOCS_DIR,
    PAPER_INDEX_DIR, CAMPUS_INDEX_DIR, FITNESS_INDEX_DIR, PSYCHOLOGY_INDEX_DIR,
    ALL_PROCESSED_IMAGES_DIR, CAMPUS_IMAGES_DIR, PAPER_IMAGES_DIR, FITNESS_IMAGES_DIR, PSYCHOLOGY_IMAGES_DIR,
    CAMPUS_PROCESSED_EXTRACTED_IMAGES, PSYCHOLOGY_PROCESSED_EXTRACTED_IMAGES,
    CAMPUS_EXTRACTED_IMAGES_JSON, PSYCHOLOGY_EXTRACTED_IMAGES_JSON,
    CAMPUS_IMAGES_PATH, PSYCHOLOGY_IMAGES_PATH,
    CAMPUS_IMAGES_MAPPING_PATH, PSYCHOLOGY_IMAGES_MAPPING_PATH
)


from ClassAssistant.LLMmodel import LLM_compus, LLM_psychology, LLM_paper, LLM_fitness

APP_ID = "c2affdebf6664d438a4043216ee15dea"
apiKey = "sk-f89e754d6cff4f31a25f609e82b3bce1"

class CampusAssistant(LLM_compus):
    def __init__(self, app_id=None):
        super().__init__(app_id or APP_ID)
        self.session_id = "campus_session"
        # åªéœ€ä¼ é€’åœºæ™¯å‚æ•°
        self.multirag = MultiRAG(scene="campus")
        print("æ ¡å›­åŠ©æ‰‹ MultiRAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def start_LLM(self):
        """
        å¯åŠ¨æ ¡å›­åŠ©æ‰‹æœåŠ¡
        """
        return "æ ¡å›­åŠ©æ‰‹ LLM model started successfully"

    def retrieve_and_answer(self, query: str, top_k: int = 8):
        """
        æ™ºèƒ½æ£€ç´¢å¹¶å›ç­”é—®é¢˜ - æ ¡å›­åŠ©æ‰‹ä¸“ç”¨

        Args:
            query (str): ç”¨æˆ·é—®é¢˜
            top_k (int): æ£€ç´¢çš„ç‰‡æ®µæ•°é‡

        Yields:
            str: ç”Ÿæˆçš„æ–‡æœ¬æ®µè½
        """
        try:
            # 1. ä½¿ç”¨MultiRAGæ£€ç´¢ç›¸å…³ç‰‡æ®µ
            print(f"æ ¡å›­åŠ©æ‰‹: æ­£åœ¨æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„top-{top_k}ç‰‡æ®µ...")
            results = self.multirag.retrieve(query, topk=top_k)

            if not results:
                print("æ ¡å›­åŠ©æ‰‹: æœªæ‰¾åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨é€šç”¨çŸ¥è¯†å›ç­”")
                yield from self.call_llm_stream(query, [])
                return

            # 2. å¤„ç†æ£€ç´¢ç»“æœ
            text_chunks = []
            image_info = []

            for result in results:
                result_type = result.get('type', 0)
                document = result.get('document', '')
                source = result.get('source', '')

                if result_type == 1:
                    if source and source != "":
                        image_info.append({
                            'description': document,
                            'path': source,
                            'score': 1.0
                        })
                        text_chunks.append(f"[å›¾ç‰‡å†…å®¹] {document} [å›¾ç‰‡åœ°å€: {source}]")
                    else:
                        text_chunks.append(f"[å›¾ç‰‡å†…å®¹] {document}")
                else:
                    text_chunks.append(document)

            print(f"æ ¡å›­åŠ©æ‰‹: æ£€ç´¢åˆ° {len(text_chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µï¼Œ{len(image_info)} ä¸ªå›¾ç‰‡")

            # 3. æ„å»ºå¢å¼ºçš„prompt
            enhanced_chunks = self._enhance_chunks_with_images(text_chunks, image_info)

            # 4. è°ƒç”¨çˆ¶ç±»çš„æµå¼ç”Ÿæˆæ–¹æ³•
            yield from self.call_llm_stream(query, enhanced_chunks)

        except Exception as e:
            print(f"æ ¡å›­åŠ©æ‰‹æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            yield from self.call_llm_stream(query, [])

    def _enhance_chunks_with_images(self, text_chunks, image_info):
        """
        æ ¹æ®å›¾ç‰‡ä¿¡æ¯å¢å¼ºæ–‡æœ¬ç‰‡æ®µ
        """
        enhanced_chunks = text_chunks.copy()

        if image_info:
            image_instruction = "\næ³¨æ„ï¼šå›ç­”ä¸­å¦‚éœ€å¼•ç”¨å›¾ç‰‡ï¼Œè¯·ç›´æ¥ä½¿ç”¨å›¾ç‰‡åœ°å€ï¼Œæ ¼å¼ä¸ºï¼š[å…·ä½“è·¯å¾„]\n"
            enhanced_chunks.append(image_instruction)

            image_summary = "å¯ç”¨å›¾ç‰‡èµ„æºï¼š\n"
            for i, img in enumerate(image_info[:3]):
                image_summary += f"{i + 1}. {img['description']} [åœ°å€: {img['path']}]\n"
            enhanced_chunks.append(image_summary)

        return enhanced_chunks

    def call_llm_stream(self, query, list):
        """
        é‡å†™çˆ¶ç±»çš„æµå¼ç”Ÿæˆæ–¹æ³•ï¼Œæ·»åŠ æ ¡å›­åŠ©æ‰‹ä¸“ç”¨çš„æç¤ºè¯å¢å¼º
        """
        separator = "\n\n"
        # ä½¿ç”¨çˆ¶ç±»çš„ç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶æ·»åŠ æ ¡å›­ä¸“ç”¨å¢å¼º
        system_prompt = self.get_stream_system_prompt()
        
        prompt = f"""{system_prompt}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œä¸‹é¢çš„èƒŒæ™¯çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {query}

èƒŒæ™¯çŸ¥è¯†:
{separator.join(list)}

å›ç­”è¦æ±‚ï¼š
1. æ¨¡ä»¿äººç±»å£å»ï¼Œå‹å¥½è‡ªç„¶åœ°è¿›è¡Œåˆ†æ®µè¯´æ˜ã€‚
2. å°†å®Œæ•´çš„å›ç­”åˆ†æˆ3åˆ°5æ®µï¼Œæ®µä¸æ®µä¹‹é—´è¦åœ¨è¯­ä¹‰å’Œé€»è¾‘ä¸Šç›¸äº’æ‰¿æ¥ï¼Œæ®µè½ä¹‹é—´å¿…é¡»ç”¨ `[NEW_PARAGRAPH]` åˆ†éš”ã€‚
3. å¦‚æœèƒŒæ™¯çŸ¥è¯†ä¸­åŒ…å«å›¾ç‰‡ä¿¡æ¯ï¼ˆæ ‡æ³¨ä¸º[å›¾ç‰‡å†…å®¹]æˆ–[å›¾ç‰‡åœ°å€]ï¼‰ï¼Œè¯·åœ¨å›ç­”ä¸­é€‚å½“å¼•ç”¨ã€‚
4. å¼•ç”¨å›¾ç‰‡æ—¶ï¼Œç›´æ¥ä½¿ç”¨æä¾›çš„å›¾ç‰‡åœ°å€ï¼Œæ ¼å¼ï¼š[å…·ä½“è·¯å¾„]ï¼Œæ— éœ€ä»»ä½•å‰ç¼€æˆ–åç¼€ã€‚
5. è‹¥ç”¨æˆ·é—®é¢˜ä¸èƒŒæ™¯çŸ¥è¯†æ— å…³ï¼Œåˆ™ç”¨é€šç”¨çŸ¥è¯†è§£å†³é—®é¢˜ã€‚

è¯·å¼€å§‹ä½ çš„å›ç­”ï¼š
"""

        # ä½¿ç”¨çˆ¶ç±»çš„éæµå¼è°ƒç”¨é€»è¾‘
        full_response_text = ""
        try:
            response = Application.call(
                api_key=self.api_key,
                app_id=self.app_id,
                prompt=prompt,
                session_id=self.session_id,
                stream=False
            )
            if response.status_code == HTTPStatus.OK:
                request_id = response.request_id
                print(f"æ ¡å›­åŠ©æ‰‹: æˆåŠŸè·å–åˆ°å›ç­”ï¼ŒRequest ID: {request_id}")
                full_response_text = response.output.text
            else:
                error_message = f'æ ¡å›­åŠ©æ‰‹ API Error: {response.message}'
                print(error_message)
                yield error_message
                return

        except Exception as e:
            error_message = f"æ ¡å›­åŠ©æ‰‹è°ƒç”¨LLMæ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            print(error_message)
            yield error_message
            return

        # æ ¹æ®åˆ†éš”ç¬¦åˆ‡åˆ†æ®µè½å¹¶ä¾æ¬¡è¿”å›
        paragraphs = full_response_text.split('[NEW_PARAGRAPH]')
        for para in paragraphs:
            cleaned_para = para.strip()
            if cleaned_para:
                yield cleaned_para


class PsychologyAssistant(LLM_psychology):
    def __init__(self, app_id=None):
        super().__init__(app_id or APP_ID)
        self.session_id = "psychology_session"
        # åˆå§‹åŒ–MultiRAGç³»ç»Ÿ - å¿ƒç†å­¦åœºæ™¯
        self.multirag = MultiRAG(scene="psychology")
        print("å¿ƒç†åŠ©æ‰‹ MultiRAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def start_psychology(self):
        """å¯åŠ¨å¿ƒç†å­¦åŠ©æ‰‹"""
        return "å¿ƒç†å­¦åŠ©æ‰‹å¯åŠ¨æˆåŠŸ"

    def retrieve_with_images(self, query: str, top_k: int = 8):
        """ä¿®å¤çš„æ£€ç´¢æ–¹æ³• - æ­£ç¡®ä½¿ç”¨å›¾ç‰‡æ˜ å°„æ–‡ä»¶"""
        try:
            print(f"å¿ƒç†åŠ©æ‰‹: æ­£åœ¨æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„top-{top_k}ç‰‡æ®µ...")
            
            # 1. ä½¿ç”¨MultiRAGæ£€ç´¢
            results = self.multirag.retrieve(query, topk=top_k)

            if not results:
                return {
                    "answer": "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚",
                    "images": [],
                    "total_results": 0
                }

            # 2. å¤„ç†æ£€ç´¢ç»“æœ
            text_chunks = []
            images = []

            for result in results:
                result_type = result.get('type', 0)
                document = result.get('document', '')
                source = result.get('source', '')
                score = result.get('score', 0)

                if result_type == 1:  # å›¾ç‰‡ç±»å‹
                    if source and source != "" and os.path.exists(source):
                        images.append({
                            'source': source,
                            'description': document[:100] + '...' if len(document) > 100 else document,
                            'score': score
                        })
                        text_chunks.append(f"[å›¾ç‰‡] {document}")
                        print(f"âœ… æ·»åŠ å›¾ç‰‡: {os.path.basename(source)}")
                    else:
                        text_chunks.append(f"[å›¾ç‰‡] {document}")
                        print(f"âš ï¸ å›¾ç‰‡è·¯å¾„æ— æ•ˆ: {source}")
                else:
                    text_chunks.append(document)

            print(f"å¿ƒç†åŠ©æ‰‹: æ£€ç´¢åˆ° {len(text_chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µï¼Œ{len(images)} ä¸ªå›¾ç‰‡")

            # 3. å¦‚æœå›¾ç‰‡æ•°é‡ä¸è¶³ï¼Œä¸“é—¨æ£€ç´¢å›¾ç‰‡
            if len(images) < 1:
                print(f"å¿ƒç†åŠ©æ‰‹: å›¾ç‰‡æ•°é‡ä¸è¶³ï¼Œä¸“é—¨æ£€ç´¢å›¾ç‰‡...")
                additional_images = self._retrieve_images_only(query, top_k=3)
                if additional_images:
                    print(f"å¿ƒç†åŠ©æ‰‹: ä¸“é—¨æ£€ç´¢æ‰¾åˆ° {len(additional_images)} ä¸ªé¢å¤–å›¾ç‰‡")
                    images.extend(additional_images)
                    for img in additional_images:
                        text_chunks.append(f"[å›¾ç‰‡] {img['description']}")

            # 4. æ„å»ºå¢å¼ºçš„prompt
            enhanced_chunks = self._enhance_psychology_chunks(text_chunks, images)

            # 5. è°ƒç”¨LLMç”Ÿæˆå›ç­”
            answer_generator = self.call_psychology_llm_stream(query, enhanced_chunks)
            answer = "".join(answer_generator)

            return {
                "answer": answer,
                "images": images,
                "total_results": len(results)
            }

        except Exception as e:
            print(f"å¿ƒç†åŠ©æ‰‹æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return {
                "answer": f"æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                "images": [],
                "total_results": 0
            }

    def _retrieve_images_only(self, query: str, top_k: int = 3):
        """ä¸“é—¨æ£€ç´¢å›¾ç‰‡"""
        try:
            # ä½¿ç”¨æ›´å¤§çš„topkå€¼ä¸“é—¨æ£€ç´¢å›¾ç‰‡
            image_results = self.multirag.retrieve(query, topk=top_k * 3)
            
            images = []
            for result in image_results:
                result_type = result.get('type', 0)
                if result_type == 1:  # åªå¤„ç†å›¾ç‰‡ç±»å‹
                    source = result.get('source', '')
                    document = result.get('document', '')
                    score = result.get('score', 0)
                    
                    if source and source != "" and os.path.exists(source):
                        images.append({
                            'source': source,
                            'description': document[:100] + '...' if len(document) > 100 else document,
                            'score': score
                        })
                        print(f"âœ… ä¸“é—¨æ£€ç´¢æ‰¾åˆ°å›¾ç‰‡: {os.path.basename(source)}")
                        
                        if len(images) >= top_k:  # è¾¾åˆ°ç›®æ ‡æ•°é‡å°±åœæ­¢
                            break
            
            return images
            
        except Exception as e:
            print(f"ä¸“é—¨æ£€ç´¢å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            return []
        
    def retrieve_and_answer(self, query: str, top_k: int = 5):
        """æµå¼å›ç­”çš„å…¼å®¹æ–¹æ³•"""
        result = self.retrieve_with_images(query, top_k)
        yield result["answer"]

    def _enhance_psychology_chunks(self, text_chunks, image_info):
        """
        æ ¹æ®å›¾ç‰‡ä¿¡æ¯å¢å¼ºå¿ƒç†å­¦æ–‡æœ¬ç‰‡æ®µ
        """
        enhanced_chunks = text_chunks.copy()

        if image_info:
            image_instruction = "\næ³¨æ„ï¼šå›ç­”ä¸­å¦‚éœ€å¼•ç”¨å¿ƒç†å­¦ç›¸å…³çš„å›¾ç¤ºæˆ–æ¡ˆä¾‹å›¾ç‰‡ï¼Œè¯·ç›´æ¥ä½¿ç”¨å›¾ç‰‡åœ°å€ï¼Œæ ¼å¼ä¸ºï¼š[å…·ä½“è·¯å¾„]\n"
            enhanced_chunks.append(image_instruction)

            image_summary = "å¯ç”¨å¿ƒç†å­¦å›¾ç‰‡èµ„æºï¼š\n"
            for i, img in enumerate(image_info[:3]):
                image_summary += f"{i + 1}. {img['description']} [åœ°å€: {img['source']}]\n"
            enhanced_chunks.append(image_summary)

        return enhanced_chunks

    def debug_image_mapping():
        """è°ƒè¯•å›¾ç‰‡æ˜ å°„æ–‡ä»¶"""
        mapping_file = str(PSYCHOLOGY_IMAGES_MAPPING_PATH)
    
        if not os.path.exists(mapping_file):
            print(f"âŒ å›¾ç‰‡æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
            return
    
        with open(mapping_file, 'r', encoding='utf-8') as f:
            mapping = json.load(f)
    
        print(f"ğŸ“Š å›¾ç‰‡æ˜ å°„æ–‡ä»¶è°ƒè¯•ä¿¡æ¯:")
        print(f"  æ€»å›¾ç‰‡æ•°: {len(mapping)}")
    
        # æ£€æŸ¥å‰5ä¸ªå›¾ç‰‡çš„è¯¦ç»†ä¿¡æ¯
        for i, (img_id, img_info) in enumerate(list(mapping.items())[:5]):
            image_path = img_info.get('image_path', '')
            exists = os.path.exists(image_path) if image_path else False
        
            print(f"\n{i+1}. {img_id}")
            print(f"   è·¯å¾„: {image_path} {'âœ…' if exists else 'âŒ'}")
            print(f"   æè¿°: {img_info.get('enhanced_description', '')[:100]}...")

    # åœ¨é€‚å½“çš„åœ°æ–¹è°ƒç”¨è°ƒè¯•å‡½æ•°
    debug_image_mapping()

    def call_psychology_llm_stream(self, query, list):
        """
        å¿ƒç†åŠ©æ‰‹ä¸“ç”¨çš„æµå¼ç”Ÿæˆæ–¹æ³•
        """
        separator = "\n\n"
        # ä½¿ç”¨çˆ¶ç±»çš„å¿ƒç†å­¦ç³»ç»Ÿæç¤ºè¯
        system_prompt = self.get_stream_system_prompt()
        
        prompt = f"""{system_prompt}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œä¸‹é¢çš„èƒŒæ™¯çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {query}

èƒŒæ™¯çŸ¥è¯†:
{separator.join(list)}

å›ç­”è¦æ±‚ï¼š
1. ç”¨æ¸©æš–ã€ä¸“ä¸šã€å¯Œæœ‰åŒç†å¿ƒçš„è¯­è¨€è¿›è¡Œå›ç­”ã€‚
2. å°†å®Œæ•´çš„å›ç­”åˆ†æˆ3åˆ°5æ®µï¼Œæ®µä¸æ®µä¹‹é—´è¦åœ¨è¯­ä¹‰å’Œé€»è¾‘ä¸Šç›¸äº’æ‰¿æ¥ï¼Œæ®µè½ä¹‹é—´å¿…é¡»ç”¨ `[NEW_PARAGRAPH]` åˆ†éš”ã€‚
3. å¦‚æœèƒŒæ™¯çŸ¥è¯†ä¸­åŒ…å«å¿ƒç†å­¦ç›¸å…³çš„å›¾ç‰‡ä¿¡æ¯ï¼ˆæ ‡æ³¨ä¸º[å›¾ç‰‡å†…å®¹]æˆ–[å›¾ç‰‡åœ°å€]ï¼‰ï¼Œè¯·åœ¨å›ç­”ä¸­é€‚å½“å¼•ç”¨ã€‚
4. å¼•ç”¨å›¾ç‰‡æ—¶ï¼Œç›´æ¥ä½¿ç”¨æä¾›çš„å›¾ç‰‡åœ°å€ï¼Œæ ¼å¼ï¼š[å…·ä½“è·¯å¾„]ï¼Œæ— éœ€ä»»ä½•å‰ç¼€æˆ–åç¼€ã€‚
5. è‹¥ç”¨æˆ·é—®é¢˜ä¸èƒŒæ™¯çŸ¥è¯†æ— å…³ï¼Œåˆ™ç”¨é€šç”¨å¿ƒç†å­¦çŸ¥è¯†è§£å†³é—®é¢˜ã€‚
6. ä¿æŒä¸“ä¸šæ€§ï¼ŒåŒæ—¶è¦æ¸©æš–å’Œæœ‰åŒç†å¿ƒã€‚

è¯·å¼€å§‹ä½ çš„å›ç­”ï¼š
"""

        # ä½¿ç”¨çˆ¶ç±»çš„éæµå¼è°ƒç”¨é€»è¾‘
        full_response_text = ""
        try:
            response = Application.call(
                api_key=self.api_key,
                app_id=self.app_id,
                prompt=prompt,
                session_id=self.session_id,
                stream=False
            )
            if response.status_code == HTTPStatus.OK:
                request_id = response.request_id
                print(f"å¿ƒç†åŠ©æ‰‹: æˆåŠŸè·å–åˆ°å›ç­”ï¼ŒRequest ID: {request_id}")
                full_response_text = response.output.text
            else:
                error_message = f'å¿ƒç†åŠ©æ‰‹ API Error: {response.message}'
                print(error_message)
                yield error_message
                return

        except Exception as e:
            error_message = f"å¿ƒç†åŠ©æ‰‹è°ƒç”¨LLMæ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            print(error_message)
            yield error_message
            return

        # æ ¹æ®åˆ†éš”ç¬¦åˆ‡åˆ†æ®µè½å¹¶ä¾æ¬¡è¿”å›
        paragraphs = full_response_text.split('[NEW_PARAGRAPH]')
        for para in paragraphs:
            cleaned_para = para.strip()
            if cleaned_para:
                yield cleaned_para

    def check_psychology_image_mapping():
        """æ£€æŸ¥å¿ƒç†å­¦å›¾ç‰‡æ˜ å°„æ–‡ä»¶çš„å†…å®¹"""
        mapping_file = str(PSYCHOLOGY_IMAGES_MAPPING_PATH)
    
        if not os.path.exists(mapping_file):
            print(f"âŒ å›¾ç‰‡æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
            return
    
        with open(mapping_file, 'r', encoding='utf-8') as f:
            mapping = json.load(f)
    
        print(f"ğŸ“Š å¿ƒç†å­¦å›¾ç‰‡æ˜ å°„æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  æ€»å›¾ç‰‡æ•°: {len(mapping)}")
    
        # æ£€æŸ¥å‰10ä¸ªå›¾ç‰‡çš„æè¿°
        print(f"\nğŸ” å‰10ä¸ªå›¾ç‰‡æè¿°ç¤ºä¾‹:")
        for i, (img_id, img_info) in enumerate(list(mapping.items())[:10]):
            description = img_info.get('enhanced_description', 'æ— æè¿°')
            image_path = img_info.get('image_path', 'æ— è·¯å¾„')
            exists = os.path.exists(image_path) if image_path else False
        
            print(f"  {i+1}. {img_id}")
            print(f"     æè¿°: {description[:100]}...")
            print(f"     è·¯å¾„: {image_path} {'âœ…' if exists else 'âŒ'}")
            print()

    # åœ¨é€‚å½“çš„åœ°æ–¹è°ƒç”¨è¿™ä¸ªå‡½æ•°
    check_psychology_image_mapping()

    def test_conflict_resolution_images():
        """æµ‹è¯•å†²çªè§£å†³ç›¸å…³çš„å›¾ç‰‡æ£€ç´¢"""
        psychology_rag = MultiRAG(scene="psychology")
    
        test_queries = [
            "å†²çªè§£å†³",
            "æœ‹å‹åµæ¶", 
            "äººé™…å†²çª",
            "çŸ›ç›¾è§£å†³",
            "æ²Ÿé€šæŠ€å·§",
            "æƒ…ç»ªç®¡ç†"
        ]
    
        for query in test_queries:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query}'")
            results = psychology_rag.retrieve(query, topk=10)
        
            image_results = [r for r in results if r.get('type') == 1]
            text_results = [r for r in results if r.get('type') == 0]
        
            print(f"  æ‰¾åˆ° {len(image_results)} ä¸ªå›¾ç‰‡, {len(text_results)} ä¸ªæ–‡æœ¬")
        
            for i, img in enumerate(image_results[:3]):
                print(f"    å›¾ç‰‡{i+1}: {img.get('document', '')[:80]}...")

    # è¿è¡Œæµ‹è¯•
    test_conflict_resolution_images()

#ä¸‹é¢æˆ‘æ¨¡æ‹Ÿäº†å‰©ä¸‹ä¸¤ä¸ªåŠ©æ‰‹çš„ç±»ï¼ˆæ–¹ä¾¿åœ¨Intent_answeråˆå§‹åŒ–æ—¶ç»Ÿä¸€åŠ©æ‰‹ç±»åï¼‰
# ä½†ä»–ä»¬çš„pathæœªå®šï¼Œæˆ‘å…ˆæ³¨é‡Šæ‰äº†åˆå§‹åŒ–éƒ¨åˆ†

class PaperAssistant(LLM_paper):
    def __init__(self, app_id=None):
        super().__init__(app_id or APP_ID)
        self.session_id = "paper_session"
        # åªéœ€ä¼ é€’åœºæ™¯å‚æ•°
        self.multirag = MultiRAG(scene="paper")
        print("è®ºæ–‡åŠ©æ‰‹ MultiRAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def start_paper(self):
        """
        å¯åŠ¨è®ºæ–‡åŠ©æ‰‹æœåŠ¡
        """
        return "è®ºæ–‡åŠ©æ‰‹å¯åŠ¨æˆåŠŸ"

    def retrieve_and_answer(self, query: str, top_k: int = 8):
        """
        æ™ºèƒ½æ£€ç´¢å¹¶å›ç­”é—®é¢˜ - è®ºæ–‡åŠ©æ‰‹ä¸“ç”¨

        Args:
            query (str): ç”¨æˆ·é—®é¢˜
            top_k (int): æ£€ç´¢çš„ç‰‡æ®µæ•°é‡

        Yields:
            str: ç”Ÿæˆçš„æ–‡æœ¬æ®µè½
        """
        try:
            # 1. ä½¿ç”¨MultiRAGæ£€ç´¢ç›¸å…³ç‰‡æ®µ
            print(f"è®ºæ–‡åŠ©æ‰‹: æ­£åœ¨æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„top-{top_k}ç‰‡æ®µ...")
            results = self.multirag.retrieve(query, topk=top_k)

            if not results:
                print("è®ºæ–‡åŠ©æ‰‹: æœªæ‰¾åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨é€šç”¨çŸ¥è¯†å›ç­”")
                yield from self.call_llm_stream(query, [])
                return

            # 2. å¤„ç†æ£€ç´¢ç»“æœ
            text_chunks = []
            image_info = []

            for result in results:
                result_type = result.get('type', 0)
                document = result.get('document', '')
                source = result.get('source', '')

                if result_type == 1:  # å›¾ç‰‡ç±»å‹
                    if source and source != "":
                        image_info.append({
                            'description': document,
                            'path': source,
                            'score': 1.0
                        })
                        text_chunks.append(f"[å›¾è¡¨å†…å®¹] {document} [å›¾è¡¨åœ°å€: {source}]")
                    else:
                        text_chunks.append(f"[å›¾è¡¨å†…å®¹] {document}")
                else:
                    text_chunks.append(document)

            print(f"è®ºæ–‡åŠ©æ‰‹: æ£€ç´¢åˆ° {len(text_chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µï¼Œ{len(image_info)} ä¸ªå›¾è¡¨")

            # 3. æ„å»ºå¢å¼ºçš„prompt
            enhanced_chunks = self._enhance_paper_chunks(text_chunks, image_info)

            # 4. è°ƒç”¨çˆ¶ç±»çš„æµå¼ç”Ÿæˆæ–¹æ³•
            yield from self.call_llm_stream(query, enhanced_chunks)

        except Exception as e:
            print(f"è®ºæ–‡åŠ©æ‰‹æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            yield from self.call_llm_stream(query, [])

    def _enhance_paper_chunks(self, text_chunks, image_info):
        """
        æ ¹æ®å›¾è¡¨ä¿¡æ¯å¢å¼ºè®ºæ–‡æ–‡æœ¬ç‰‡æ®µ
        """
        enhanced_chunks = text_chunks.copy()

        if image_info:
            image_instruction = "\næ³¨æ„ï¼šå›ç­”ä¸­å¦‚éœ€å¼•ç”¨è®ºæ–‡å›¾è¡¨ã€æ•°æ®å¯è§†åŒ–æˆ–å®éªŒå›¾ç¤ºï¼Œè¯·ç›´æ¥ä½¿ç”¨å›¾è¡¨åœ°å€ï¼Œæ ¼å¼ä¸ºï¼š[å…·ä½“è·¯å¾„]\n"
            enhanced_chunks.append(image_instruction)

            image_summary = "å¯ç”¨è®ºæ–‡å›¾è¡¨èµ„æºï¼š\n"
            for i, img in enumerate(image_info[:3]):
                image_summary += f"{i + 1}. {img['description']} [åœ°å€: {img['path']}]\n"
            enhanced_chunks.append(image_summary)

        return enhanced_chunks

    def call_llm_stream(self, query, list):
        """
        é‡å†™çˆ¶ç±»çš„æµå¼ç”Ÿæˆæ–¹æ³•ï¼Œæ·»åŠ è®ºæ–‡åŠ©æ‰‹ä¸“ç”¨çš„æç¤ºè¯å¢å¼º
        """
        separator = "\n\n"
        # ä½¿ç”¨çˆ¶ç±»çš„ç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶æ·»åŠ è®ºæ–‡ä¸“ç”¨å¢å¼º
        system_prompt = self.get_stream_system_prompt()
        
        prompt = f"""{system_prompt}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œä¸‹é¢çš„èƒŒæ™¯çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {query}

èƒŒæ™¯çŸ¥è¯†:
{separator.join(list)}

å›ç­”è¦æ±‚ï¼š
1. ç”¨ä¸¥è°¨ã€å­¦æœ¯ã€ä¸“ä¸šçš„è¯­è¨€è¿›è¡Œå›ç­”ï¼Œä¿æŒè®ºæ–‡å†™ä½œé£æ ¼ã€‚
2. å°†å®Œæ•´çš„å›ç­”åˆ†æˆ3åˆ°5æ®µï¼Œæ®µä¸æ®µä¹‹é—´è¦åœ¨è¯­ä¹‰å’Œé€»è¾‘ä¸Šç›¸äº’æ‰¿æ¥ï¼Œæ®µè½ä¹‹é—´å¿…é¡»ç”¨ `[NEW_PARAGRAPH]` åˆ†éš”ã€‚
3. å¦‚æœèƒŒæ™¯çŸ¥è¯†ä¸­åŒ…å«è®ºæ–‡å›¾è¡¨ã€æ•°æ®å¯è§†åŒ–æˆ–å®éªŒå›¾ç¤ºï¼ˆæ ‡æ³¨ä¸º[å›¾è¡¨å†…å®¹]æˆ–[å›¾è¡¨åœ°å€]ï¼‰ï¼Œè¯·åœ¨å›ç­”ä¸­é€‚å½“å¼•ç”¨ã€‚
4. å¼•ç”¨å›¾è¡¨æ—¶ï¼Œç›´æ¥ä½¿ç”¨æä¾›çš„å›¾è¡¨åœ°å€ï¼Œæ ¼å¼ï¼š[å…·ä½“è·¯å¾„]ï¼Œæ— éœ€ä»»ä½•å‰ç¼€æˆ–åç¼€ã€‚
5. è‹¥ç”¨æˆ·é—®é¢˜ä¸èƒŒæ™¯çŸ¥è¯†æ— å…³ï¼Œåˆ™ç”¨é€šç”¨å­¦æœ¯çŸ¥è¯†è§£å†³é—®é¢˜ã€‚
6. ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ï¼ŒåŒæ—¶è¦æ¸…æ™°æ˜“æ‡‚ã€‚

è¯·å¼€å§‹ä½ çš„å›ç­”ï¼š
"""

        # ä½¿ç”¨çˆ¶ç±»çš„éæµå¼è°ƒç”¨é€»è¾‘
        full_response_text = ""
        try:
            response = Application.call(
                api_key=self.api_key,
                app_id=self.app_id,
                prompt=prompt,
                session_id=self.session_id,
                stream=False
            )
            if response.status_code == HTTPStatus.OK:
                request_id = response.request_id
                print(f"è®ºæ–‡åŠ©æ‰‹: æˆåŠŸè·å–åˆ°å›ç­”ï¼ŒRequest ID: {request_id}")
                full_response_text = response.output.text
            else:
                error_message = f'è®ºæ–‡åŠ©æ‰‹ API Error: {response.message}'
                print(error_message)
                yield error_message
                return

        except Exception as e:
            error_message = f"è®ºæ–‡åŠ©æ‰‹è°ƒç”¨LLMæ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            print(error_message)
            yield error_message
            return

        # æ ¹æ®åˆ†éš”ç¬¦åˆ‡åˆ†æ®µè½å¹¶ä¾æ¬¡è¿”å›
        paragraphs = full_response_text.split('[NEW_PARAGRAPH]')
        for para in paragraphs:
            cleaned_para = para.strip()
            if cleaned_para:
                yield cleaned_para

class FitnessAssistant(LLM_fitness):
    def __init__(self, app_id=None):
        super().__init__(app_id or APP_ID)
        self.session_id = "fitness_session"
        # åªéœ€ä¼ é€’åœºæ™¯å‚æ•°
        self.multirag = MultiRAG(scene="fitness")
        print("å¥åº·é¥®é£ŸåŠ©æ‰‹ MultiRAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def start_fitness(self):
        """
        å¯åŠ¨å¥åº·é¥®é£ŸåŠ©æ‰‹æœåŠ¡
        """
        return "å¥åº·é¥®é£ŸåŠ©æ‰‹å¯åŠ¨æˆåŠŸ"

    def retrieve_and_answer(self, query: str, top_k: int = 8):
        """
        æ™ºèƒ½æ£€ç´¢å¹¶å›ç­”é—®é¢˜ - å¥åº·é¥®é£ŸåŠ©æ‰‹ä¸“ç”¨

        Args:
            query (str): ç”¨æˆ·é—®é¢˜
            top_k (int): æ£€ç´¢çš„ç‰‡æ®µæ•°é‡

        Yields:
            str: ç”Ÿæˆçš„æ–‡æœ¬æ®µè½
        """
        try:
            # 1. ä½¿ç”¨MultiRAGæ£€ç´¢ç›¸å…³ç‰‡æ®µ
            print(f"å¥åº·é¥®é£ŸåŠ©æ‰‹: æ­£åœ¨æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„top-{top_k}ç‰‡æ®µ...")
            results = self.multirag.retrieve(query, topk=top_k)

            if not results:
                print("å¥åº·é¥®é£ŸåŠ©æ‰‹: æœªæ‰¾åˆ°ç›¸å…³ç‰‡æ®µï¼Œä½¿ç”¨é€šç”¨çŸ¥è¯†å›ç­”")
                yield from self.call_llm_stream(query, [])
                return

            # 2. å¤„ç†æ£€ç´¢ç»“æœ
            text_chunks = []
            image_info = []

            for result in results:
                result_type = result.get('type', 0)
                document = result.get('document', '')
                source = result.get('source', '')

                if result_type == 1:  # å›¾ç‰‡ç±»å‹
                    if source and source != "":
                        image_info.append({
                            'description': document,
                            'path': source,
                            'score': 1.0
                        })
                        text_chunks.append(f"[åŠ¨ä½œå›¾ç¤º] {document} [å›¾ç¤ºåœ°å€: {source}]")
                    else:
                        text_chunks.append(f"[åŠ¨ä½œå›¾ç¤º] {document}")
                else:
                    text_chunks.append(document)

            print(f"å¥åº·é¥®é£ŸåŠ©æ‰‹: æ£€ç´¢åˆ° {len(text_chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µï¼Œ{len(image_info)} ä¸ªåŠ¨ä½œå›¾ç¤º")

            # 3. æ„å»ºå¢å¼ºçš„prompt
            enhanced_chunks = self._enhance_fitness_chunks(text_chunks, image_info)

            # 4. è°ƒç”¨çˆ¶ç±»çš„æµå¼ç”Ÿæˆæ–¹æ³•
            yield from self.call_llm_stream(query, enhanced_chunks)

        except Exception as e:
            print(f"å¥åº·é¥®é£ŸåŠ©æ‰‹æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            yield from self.call_llm_stream(query, [])

    def _enhance_fitness_chunks(self, text_chunks, image_info):
        """
        æ ¹æ®åŠ¨ä½œå›¾ç¤ºä¿¡æ¯å¢å¼ºå¥èº«æ–‡æœ¬ç‰‡æ®µ
        """
        enhanced_chunks = text_chunks.copy()

        if image_info:
            image_instruction = "\næ³¨æ„ï¼šå›ç­”ä¸­å¦‚éœ€å¼•ç”¨å¥èº«åŠ¨ä½œå›¾ç¤ºã€è¥å…»å›¾è¡¨æˆ–è§£å‰–å›¾ç¤ºï¼Œè¯·ç›´æ¥ä½¿ç”¨å›¾ç¤ºåœ°å€ï¼Œæ ¼å¼ä¸ºï¼š[å…·ä½“è·¯å¾„]\n"
            enhanced_chunks.append(image_instruction)

            image_summary = "å¯ç”¨å¥åº·é¥®é£Ÿå›¾ç¤ºèµ„æºï¼š\n"
            for i, img in enumerate(image_info[:3]):
                image_summary += f"{i + 1}. {img['description']} [åœ°å€: {img['path']}]\n"
            enhanced_chunks.append(image_summary)

        return enhanced_chunks

    def call_llm_stream(self, query, list):
        """
        é‡å†™çˆ¶ç±»çš„æµå¼ç”Ÿæˆæ–¹æ³•ï¼Œæ·»åŠ å¥åº·é¥®é£ŸåŠ©æ‰‹ä¸“ç”¨çš„æç¤ºè¯å¢å¼º
        """
        separator = "\n\n"
        # ä½¿ç”¨çˆ¶ç±»çš„ç³»ç»Ÿæç¤ºè¯ï¼Œå¹¶æ·»åŠ å¥èº«ä¸“ç”¨å¢å¼º
        system_prompt = self.get_stream_system_prompt()
        
        prompt = f"""{system_prompt}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œä¸‹é¢çš„èƒŒæ™¯çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚

ç”¨æˆ·é—®é¢˜: {query}

èƒŒæ™¯çŸ¥è¯†:
{separator.join(list)}

å›ç­”è¦æ±‚ï¼š
1. ç”¨é¼“åŠ±ã€ä¸“ä¸šã€å®ç”¨çš„è¯­è¨€è¿›è¡Œå›ç­”ï¼Œä¿æŒå¥èº«æ•™ç»ƒé£æ ¼ã€‚
2. å°†å®Œæ•´çš„å›ç­”åˆ†æˆ3åˆ°5æ®µï¼Œæ®µä¸æ®µä¹‹é—´è¦åœ¨è¯­ä¹‰å’Œé€»è¾‘ä¸Šç›¸äº’æ‰¿æ¥ï¼Œæ®µè½ä¹‹é—´å¿…é¡»ç”¨ `[NEW_PARAGRAPH]` åˆ†éš”ã€‚
3. å¦‚æœèƒŒæ™¯çŸ¥è¯†ä¸­åŒ…å«å¥èº«åŠ¨ä½œå›¾ç¤ºã€è¥å…»å›¾è¡¨æˆ–è§£å‰–å›¾ç¤ºï¼ˆæ ‡æ³¨ä¸º[åŠ¨ä½œå›¾ç¤º]æˆ–[å›¾ç¤ºåœ°å€]ï¼‰ï¼Œè¯·åœ¨å›ç­”ä¸­é€‚å½“å¼•ç”¨ã€‚
4. å¼•ç”¨å›¾ç¤ºæ—¶ï¼Œç›´æ¥ä½¿ç”¨æä¾›çš„å›¾ç¤ºåœ°å€ï¼Œæ ¼å¼ï¼š[å…·ä½“è·¯å¾„]ï¼Œæ— éœ€ä»»ä½•å‰ç¼€æˆ–åç¼€ã€‚
5. è‹¥ç”¨æˆ·é—®é¢˜ä¸èƒŒæ™¯çŸ¥è¯†æ— å…³ï¼Œåˆ™ç”¨é€šç”¨å¥èº«è¥å…»çŸ¥è¯†è§£å†³é—®é¢˜ã€‚
6. ä¿æŒä¸“ä¸šæ€§ï¼ŒåŒæ—¶è¦é¼“åŠ±å’Œæ”¯æŒç”¨æˆ·ã€‚

è¯·å¼€å§‹ä½ çš„å›ç­”ï¼š
"""

        # ä½¿ç”¨çˆ¶ç±»çš„éæµå¼è°ƒç”¨é€»è¾‘
        full_response_text = ""
        try:
            response = Application.call(
                api_key=self.api_key,
                app_id=self.app_id,
                prompt=prompt,
                session_id=self.session_id,
                stream=False
            )
            if response.status_code == HTTPStatus.OK:
                request_id = response.request_id
                print(f"å¥åº·é¥®é£ŸåŠ©æ‰‹: æˆåŠŸè·å–åˆ°å›ç­”ï¼ŒRequest ID: {request_id}")
                full_response_text = response.output.text
            else:
                error_message = f'å¥åº·é¥®é£ŸåŠ©æ‰‹ API Error: {response.message}'
                print(error_message)
                yield error_message
                return

        except Exception as e:
            error_message = f"å¥åº·é¥®é£ŸåŠ©æ‰‹è°ƒç”¨LLMæ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            print(error_message)
            yield error_message
            return

        # æ ¹æ®åˆ†éš”ç¬¦åˆ‡åˆ†æ®µè½å¹¶ä¾æ¬¡è¿”å›
        paragraphs = full_response_text.split('[NEW_PARAGRAPH]')
        for para in paragraphs:
            cleaned_para = para.strip()
            if cleaned_para:
                yield cleaned_para