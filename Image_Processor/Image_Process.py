import os
import sys
import base64
import io
import re
import concurrent.futures
import hashlib
from typing import List, Dict, Tuple, Optional, Set
from docx import Document
from docx.shared import Inches
from docx.document import Document as DocumentType
from docx.oxml.table import CT_Tbl
from docx.oxml.text.paragraph import CT_P
from docx.table import _Cell, Table
from docx.text.paragraph import Paragraph
from PIL import Image
import numpy as np
from openai import OpenAI
import json
import time
import pickle
from tqdm import tqdm

current_dir = os.path.dirname(os.path.abspath(__file__)) 
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

from Utils.Path import (
    PAPER_DOCS_DIR, CAMPUS_DOCS_DIR, FITNESS_DOCS_DIR, PSYCHOLOGY_DOCS_DIR,
    PAPER_INDEX_DIR, CAMPUS_INDEX_DIR, FITNESS_INDEX_DIR, PSYCHOLOGY_INDEX_DIR,
    ALL_PROCESSED_IMAGES_DIR, CAMPUS_IMAGES_DIR, PAPER_IMAGES_DIR, FITNESS_IMAGES_DIR, PSYCHOLOGY_IMAGES_DIR,
    CAMPUS_PROCESSED_EXTRACTED_IMAGES, PSYCHOLOGY_PROCESSED_EXTRACTED_IMAGES,
    CAMPUS_EXTRACTED_IMAGES_JSON, PSYCHOLOGY_EXTRACTED_IMAGES_JSON,
    CAMPUS_IMAGES_PATH, PSYCHOLOGY_IMAGES_PATH
)


class ImageExtractor:
    """ä»Wordæ–‡æ¡£ä¸­æå–å›¾ç‰‡åŠå…¶ä¸Šä¸‹æ–‡çš„ç±»"""

    def __init__(self, debug_folder: str, output_dir: str = None):
        self.debug_folder = debug_folder
        self.output_dir = output_dir
        
        # æ ¹æ®è¾“å…¥æ–‡ä»¶å¤¹è‡ªåŠ¨åˆ¤æ–­åœºæ™¯
        self.scene = self._detect_scene(debug_folder)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨åŸºäºåœºæ™¯çš„é»˜è®¤ç›®å½•
        if not self.output_dir:
            if self.scene == "campus":
                self.output_dir = str(CAMPUS_IMAGES_PATH)
            elif self.scene == "psychology":
                self.output_dir = str(PSYCHOLOGY_IMAGES_PATH)
            else:
                self.output_dir = os.path.join(os.path.dirname(debug_folder), "extracted_images")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"ImageExtractoråˆå§‹åŒ–:")
        print(f"  åœºæ™¯: {self.scene}")
        print(f"  è¾“å…¥ç›®å½•: {debug_folder}")
        print(f"  è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # åˆå§‹åŒ–Qwen3-VLå®¢æˆ·ç«¯
        self.qwen3_vl_client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key='ms-56e481ae-fc65-4c3e-8b7c-88d7d9964dcb'
        )

        # åˆå§‹åŒ–Qwen3.0å®¢æˆ·ç«¯
        self.qwen3_client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key='ms-56e481ae-fc65-4c3e-8b7c-88d7d9964dcb'
        )

    def _detect_scene(self, folder_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶å¤¹è·¯å¾„è‡ªåŠ¨æ£€æµ‹åœºæ™¯"""
        folder_path_lower = folder_path.lower()
        if 'campus' in folder_path_lower:
            return "campus"
        elif 'psychology' in folder_path_lower or 'psych' in folder_path_lower:
            return "psychology"
        else:
            # ä»è·¯å¾„ä¸­æå–åœºæ™¯ä¿¡æ¯
            folder_name = os.path.basename(folder_path)
            if 'campus' in folder_name.lower():
                return "campus"
            elif 'psychology' in folder_name.lower() or 'psych' in folder_name.lower():
                return "psychology"
            else:
                return "unknown"

    def extract_images_from_docx(self, docx_path: str) -> List[Dict]:
        """ä»Wordæ–‡æ¡£ä¸­æå–å›¾ç‰‡åŠå…¶ä¸Šä¸‹æ–‡"""
        doc = Document(docx_path)
        images_data = []

        # è·å–æ‰€æœ‰æ®µè½æ–‡æœ¬
        paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]

        # éå†æ–‡æ¡£ä¸­çš„æ‰€æœ‰æ®µè½ï¼ŒæŸ¥æ‰¾åŒ…å«å›¾ç‰‡çš„æ®µè½
        for para_idx, paragraph in enumerate(doc.paragraphs):
            for run in paragraph.runs:
                # æŸ¥æ‰¾å›¾ç‰‡å…ƒç´ 
                for drawing in run.element.xpath('.//a:blip'):
                    try:
                        # è·å–å›¾ç‰‡çš„å…³ç³»ID
                        embed_id = drawing.get(
                            '{http://schemas.openxmlformats.org/officeDocument/2006/relationships}embed')
                        if embed_id:
                            # é€šè¿‡å…³ç³»IDè·å–å›¾ç‰‡æ•°æ®
                            image_part = doc.part.related_parts[embed_id]
                            image_data = image_part.blob

                            # è·å–ä¸Šä¸‹æ–‡
                            context_before = ""
                            context_after = ""

                            # è·å–å›¾ç‰‡å‰åçš„æ®µè½ä½œä¸ºä¸Šä¸‹æ–‡
                            if para_idx > 0:
                                context_before = " ".join(
                                    [p.text.strip() for p in doc.paragraphs[max(0, para_idx - 2):para_idx] if
                                     p.text.strip()])[:200]
                            if para_idx < len(doc.paragraphs) - 1:
                                context_after = " ".join([p.text.strip() for p in doc.paragraphs[
                                                                                  para_idx + 1:min(len(doc.paragraphs),
                                                                                                   para_idx + 3)] if
                                                          p.text.strip()])[:200]

                            images_data.append({
                                'image_data': image_data,
                                'context_before': context_before,
                                'context_after': context_after,
                                'source_file': os.path.basename(docx_path),
                                'source_path': docx_path,
                                'paragraph_index': para_idx
                            })
                    except Exception as e:
                        print(f"æå–å›¾ç‰‡æ—¶å‡ºé”™: {e}")
                        continue

        return images_data

    def image_to_base64(self, image_data: bytes) -> str:
        """å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸ºbase64ç¼–ç """
        return base64.b64encode(image_data).decode('utf-8')

    def describe_image_with_qwen3_vl(self, image_data: bytes) -> str:
        """ä½¿ç”¨Qwen3-VLè¯†åˆ«å›¾ç‰‡å†…å®¹ï¼Œæ— é™é‡è¯•ç›´åˆ°æˆåŠŸ"""
        attempt = 0
        max_wait_time = 300  # æœ€å¤§ç­‰å¾…5åˆ†é’Ÿ
    
        while True:
            attempt += 1
            try:
                print(f"å¼€å§‹è°ƒç”¨Qwen3-VL API... (å°è¯• {attempt})")
            
                # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64
                base64_image = self.image_to_base64(image_data)
                image_url = f"data:image/jpeg;base64,{base64_image}"
            
                print(f"å›¾ç‰‡base64é•¿åº¦: {len(base64_image)}")
                print(f"å‡†å¤‡å‘é€è¯·æ±‚åˆ°æ¨¡å‹: Qwen/Qwen3-VL-235B-A22B-Instruct")

                response = self.qwen3_vl_client.chat.completions.create(
                    model='Qwen/Qwen3-VL-235B-A22B-Instruct',
                    messages=[{
                        'role': 'user',
                        'content': [{
                            'type': 'text',
                            'text': 'è¯·è¯¦ç»†æè¿°è¿™å¹…å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬å›¾ç‰‡ä¸­çš„æ–‡å­—ã€å›¾å½¢ã€å¸ƒå±€ç­‰æ‰€æœ‰å¯è§å…ƒç´ ã€‚',
                        }, {
                            'type': 'image_url',
                            'image_url': {
                                'url': image_url,
                            },
                        }],
                    }],
                    stream=False,
                )

                result = response.choices[0].message.content
                print(f"Qwen3-VLå“åº”æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(result)}")
                return result
            
            except Exception as e:
                error_msg = str(e)
                print(f"Qwen3-VLè¯†åˆ«å›¾ç‰‡æ—¶å‡ºé”™ (å°è¯• {attempt}): {error_msg}")
            
                if "429" in error_msg or "quota" in error_msg.lower():
                    # APIé™åˆ¶ï¼Œç­‰å¾…æŒ‡æ•°å¢é•¿çš„æ—¶é—´
                    wait_time = min(2 ** attempt, max_wait_time)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§5åˆ†é’Ÿ
                    print(f"APIé™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time
                    time.sleep(wait_time)
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œç­‰å¾…è¾ƒçŸ­æ—¶é—´åé‡è¯•
                    wait_time = min(attempt * 10, 60)  # çº¿æ€§å¢é•¿ï¼Œæœ€å¤§1åˆ†é’Ÿ
                    print(f"APIé”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time
                    time.sleep(wait_time)

    def enhance_description_with_qwen3(self, image_description: str, context_before: str, context_after: str) -> str:
        """ä½¿ç”¨Qwen3.0ç»“åˆä¸Šä¸‹æ–‡å®Œå–„å›¾ç‰‡æè¿°ï¼Œæ— é™é‡è¯•ç›´åˆ°æˆåŠŸ"""
        attempt = 0
        max_wait_time = 300  # æœ€å¤§ç­‰å¾…5åˆ†é’Ÿ
    
        while True:
            attempt += 1
            try:
                print(f"å¼€å§‹è°ƒç”¨Qwen3.0 API... (å°è¯• {attempt})")
            
                prompt = f"""
                è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€æ®µå®Œæ•´çš„å›¾ç‰‡å†…å®¹æè¿°ï¼š

                å›¾ç‰‡è¯†åˆ«ç»“æœï¼š{image_description}

                ä¸Šæ–‡å†…å®¹ï¼š{context_before}

                ä¸‹æ–‡å†…å®¹ï¼š{context_after}

                è¯·ç»“åˆä¸Šä¸‹æ–‡ï¼Œåˆ†æè¿™å¼ å›¾ç‰‡çš„åº”ç”¨åœºæ™¯ã€ä¸»é¢˜å’Œä½œç”¨ï¼Œå¹¶ç”Ÿæˆä¸€æ®µå®Œæ•´ã€å‡†ç¡®çš„æè¿°ã€‚
                """

                print(f"Qwen3.0æç¤ºè¯é•¿åº¦: {len(prompt)}")
                print(f"å‡†å¤‡å‘é€è¯·æ±‚åˆ°æ¨¡å‹: Qwen/Qwen3-235B-A22B-Instruct-2507")

                response = self.qwen3_client.chat.completions.create(
                    model='Qwen/Qwen3-235B-A22B-Instruct-2507',
                    messages=[
                        {
                            'role': 'system',
                            'content': 'You are a helpful assistant that analyzes images in context.'
                        },
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ],
                    stream=False,
                )

                result = response.choices[0].message.content.strip()
                print(f"Qwen3.0å“åº”æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(result)}")
                return result
            
            except Exception as e:
                error_msg = str(e)
                print(f"Qwen3.0å®Œå–„æè¿°æ—¶å‡ºé”™ (å°è¯• {attempt}): {error_msg}")
            
                if "429" in error_msg or "quota" in error_msg.lower():
                    # APIé™åˆ¶ï¼Œç­‰å¾…æŒ‡æ•°å¢é•¿çš„æ—¶é—´
                    wait_time = min(2 ** attempt, max_wait_time)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§5åˆ†é’Ÿ
                    print(f"APIé™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time
                    time.sleep(wait_time)
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œç­‰å¾…è¾ƒçŸ­æ—¶é—´åé‡è¯•
                    wait_time = min(attempt * 10, 60)  # çº¿æ€§å¢é•¿ï¼Œæœ€å¤§1åˆ†é’Ÿ
                    print(f"APIé”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time
                    time.sleep(wait_time)

    def _generate_image_filename(self, source_file: str, image_index: int, image_data: bytes) -> str:
        """ç”Ÿæˆç»Ÿä¸€çš„å›¾ç‰‡æ–‡ä»¶å - ä¿®å¤ç‰ˆæœ¬"""
        source_name = os.path.splitext(os.path.basename(source_file))[0]
    
        # ä½¿ç”¨å›¾ç‰‡å†…å®¹ç”Ÿæˆå®Œæ•´çš„16ä½MD5å“ˆå¸Œï¼ˆä¸å›¾ç‰‡å“ˆå¸Œä¿æŒä¸€è‡´ï¼‰
        image_hash = hashlib.md5(image_data).hexdigest()[:16]
    
        # ç»Ÿä¸€å‘½åæ ¼å¼ï¼šæºæ–‡ä»¶_image_ç´¢å¼•_å®Œæ•´16ä½å“ˆå¸Œ.jpg
        # ä¾‹å¦‚ï¼šæ ¡å›­é‚®ç®±æ”»ç•¥_image_1_5ddf82a0ab52477b.jpg
        filename = f"{source_name}_image_{image_index}_{image_hash}.jpg"
    
        print(f"ç”Ÿæˆç»Ÿä¸€æ–‡ä»¶å: {filename} (å“ˆå¸Œ: {image_hash})")
        return filename

    def _save_image_file(self, image_data: bytes, filename: str) -> str:
        """ä¿å­˜å›¾ç‰‡æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•"""
        image_path = os.path.join(self.output_dir, filename)
        
        try:
            with open(image_path, 'wb') as f:
                f.write(image_data)
            print(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {filename}")
            return image_path
        except Exception as e:
            print(f"âŒ ä¿å­˜å›¾ç‰‡å¤±è´¥ {filename}: {e}")
            return ""

    def process_all_documents(self, processed_hashes: Set[str] = None) -> List[Dict]:
        """å¤„ç†debugæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Wordæ–‡æ¡£ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰ï¼Œæ”¯æŒå¢é‡å¤„ç†"""
        if processed_hashes is None:
            processed_hashes = set()
            
        all_processed_images = []
        json_file_path = self._get_scene_json_path()

        # é€’å½’è·å–æ‰€æœ‰docxæ–‡ä»¶
        docx_files = []
        for root, dirs, files in os.walk(self.debug_folder):
            for file in files:
                # è·³è¿‡ä¸´æ—¶æ–‡ä»¶
                if file.startswith('~$') or file.startswith('.') or file in ['Thumbs.db', '.DS_Store']:
                    continue
                if file.endswith('.docx'):
                    docx_files.append(os.path.join(root, file))
    
        print(f"æ‰¾åˆ° {len(docx_files)} ä¸ªWordæ–‡æ¡£ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰")
    
        for docx_path in docx_files:
            print(f"\nå¤„ç†æ–‡æ¡£: {docx_path}")
        
            try:
                # æå–å›¾ç‰‡
                images_data = self.extract_images_from_docx(docx_path)
                print(f"ä» {os.path.basename(docx_path)} ä¸­æå–åˆ° {len(images_data)} å¼ å›¾ç‰‡")
    
                for i, img_data in enumerate(images_data):
                    # è®¡ç®—å›¾ç‰‡å“ˆå¸Œ
                    image_hash = hashlib.md5(img_data['image_data']).hexdigest()[:16]
                    
                    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å·²å¤„ç†è¿‡
                    if image_hash in processed_hashes:
                        print(f"  è·³è¿‡å·²å¤„ç†çš„å›¾ç‰‡ {i+1}/{len(images_data)} (å“ˆå¸Œ: {image_hash})")
                        continue
                    
                    print(f"  å¤„ç†å›¾ç‰‡ {i + 1}/{len(images_data)}...")
    
                    # ç”Ÿæˆç»Ÿä¸€çš„æ–‡ä»¶å - ä½¿ç”¨å®Œæ•´çš„16ä½å“ˆå¸Œ
                    source_file = img_data['source_file']
                    filename = self._generate_image_filename(source_file, i + 1, img_data['image_data'])
                    
                    # ä¿å­˜å›¾ç‰‡æ–‡ä»¶
                    image_path = self._save_image_file(img_data['image_data'], filename)
                    
                    if not image_path:
                        continue  # å¦‚æœä¿å­˜å¤±è´¥ï¼Œè·³è¿‡è¿™å¼ å›¾ç‰‡
    
                    # ä½¿ç”¨Qwen3-VLè¯†åˆ«å›¾ç‰‡ï¼ˆæ— é™é‡è¯•ï¼‰
                    try:
                        image_description = self.describe_image_with_qwen3_vl(img_data['image_data'])
                        print(f"    å›¾ç‰‡è¯†åˆ«å®Œæˆ")
                    except Exception as e:
                        print(f"    âŒ å›¾ç‰‡è¯†åˆ«å¤±è´¥: {e}")
                        image_description = f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}"
    
                    # ä½¿ç”¨Qwen3.0å®Œå–„æè¿°ï¼ˆæ— é™é‡è¯•ï¼‰
                    try:
                        enhanced_description = self.enhance_description_with_qwen3(
                            image_description,
                            img_data['context_before'],
                            img_data['context_after']
                        )
                        print(f"    æè¿°å®Œå–„å®Œæˆ")
                    except Exception as e:
                        print(f"    âŒ æè¿°å®Œå–„å¤±è´¥: {e}")
                        enhanced_description = f"{image_description} [æè¿°å®Œå–„å¤±è´¥: {str(e)}]"
    
                    # æ„å»ºå¤„ç†åçš„å›¾ç‰‡æ•°æ®
                    processed_img = {
                        'context_before': img_data['context_before'],
                        'context_after': img_data['context_after'],
                        'source_file': source_file,
                        'source_path': img_data['source_path'],
                        'image_path': image_path,
                        'image_filename': filename,
                        'saved_path': image_path,
                        'processed_path': image_path,
                        'original_description': image_description,
                        'enhanced_description': enhanced_description,
                        'image_hash': image_hash,  # ä½¿ç”¨ä»æ–‡ä»¶åæå–çš„å“ˆå¸Œ
                        'scene': self.scene,
                        'paragraph_index': img_data.get('paragraph_index', 0)
                    }
                    
                    # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                    all_processed_images.append(processed_img)
                    
                    # ç«‹å³å†™å…¥JSONæ–‡ä»¶
                    self._append_to_json(processed_img, json_file_path)
                    
                    # æ·»åŠ åˆ°å·²å¤„ç†å“ˆå¸Œé›†åˆ
                    processed_hashes.add(image_hash)
                    
                    # å¢åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                    delay = 5  # ç»Ÿä¸€5ç§’å»¶è¿Ÿ
                    print(f"    ç­‰å¾… {delay} ç§’é¿å…APIé™åˆ¶...")
                    time.sleep(delay)

            except Exception as e:
                print(f"å¤„ç†æ–‡æ¡£ {docx_path} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"\nâœ… å›¾ç‰‡å¤„ç†å®Œæˆ: å…±å¤„ç† {len(all_processed_images)} å¼ å›¾ç‰‡")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        return all_processed_images

    def _get_scene_json_path(self) -> str:
        """è·å–åœºæ™¯å¯¹åº”çš„JSONæ–‡ä»¶è·¯å¾„"""
        if self.scene == "campus":
            return str(CAMPUS_EXTRACTED_IMAGES_JSON)
        elif self.scene == "psychology":
            return str(PSYCHOLOGY_EXTRACTED_IMAGES_JSON)
        else:
            return os.path.join(self.output_dir, f"{self.scene}_extracted_images.json")

    def _append_to_json(self, img_data: Dict, json_path: str):
        """å°†å›¾ç‰‡æ•°æ®è¿½åŠ åˆ°JSONæ–‡ä»¶"""
        # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(json_path):
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump([], f, ensure_ascii=False, indent=2)
        
        # è¯»å–ç°æœ‰æ•°æ®
        existing_data = []
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except Exception as e:
            print(f"è¯»å–JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            existing_data = []
        
        # æ·»åŠ æ–°æ•°æ®
        existing_data.append(img_data)
        
        # å†™å›æ–‡ä»¶
        try:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… å›¾ç‰‡æ•°æ®å·²è¿½åŠ åˆ°JSONæ–‡ä»¶: {json_path}")
        except Exception as e:
            print(f"âŒ å†™å…¥JSONæ–‡ä»¶å¤±è´¥: {e}")

    def _verify_filename_consistency(self, processed_images: List[Dict]):
        """éªŒè¯æ–‡ä»¶åä¸€è‡´æ€§"""
        print("\n=== éªŒè¯æ–‡ä»¶åä¸€è‡´æ€§ ===")
    
        consistent_count = 0
        inconsistent_count = 0
    
        for img_data in processed_images:
            filename = img_data.get('image_filename', '')
            stored_hash = img_data.get('image_hash', '')
        
            # ä»æ–‡ä»¶åä¸­æå–å“ˆå¸Œ
            if '_image_' in filename:
                # åŒ¹é…_image_åé¢çš„å“ˆå¸Œå€¼ï¼ˆå‡è®¾å“ˆå¸Œæ˜¯16ä½åå…­è¿›åˆ¶æ•°ï¼‰
                match = re.search(r'_image_.*?([a-f0-9]{16})\.', filename)
                if match:
                    hash_from_filename = match.group(1)
                    # æ£€æŸ¥å“ˆå¸Œæ˜¯å¦ä¸€è‡´
                    if hash_from_filename == stored_hash and len(stored_hash) == 16:
                        consistent_count += 1
                    else:
                        inconsistent_count += 1
                        print(f"âŒ ä¸ä¸€è‡´: æ–‡ä»¶åå“ˆå¸Œ={hash_from_filename}, å­˜å‚¨å“ˆå¸Œ={stored_hash}")
    
        print(f"ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ:")
        print(f"  âœ… ä¸€è‡´çš„æ–‡ä»¶: {consistent_count}")
        print(f"  âŒ ä¸ä¸€è‡´çš„æ–‡ä»¶: {inconsistent_count}")
    
        if inconsistent_count == 0:
            print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶åå’Œå“ˆå¸Œå®Œå…¨ä¸€è‡´ï¼")
        else:
            print("âš ï¸ å­˜åœ¨ä¸ä¸€è‡´çš„æ–‡ä»¶ï¼Œéœ€è¦ä¿®å¤")

    def save_images_to_word(self, processed_images: List[Dict], output_path: str):
        """å°†å¤„ç†åçš„å›¾ç‰‡å’Œæè¿°ä¿å­˜åˆ°Wordæ–‡æ¡£"""
        doc = Document()
        doc.add_heading('æå–çš„å›¾ç‰‡åŠå…¶æè¿°', 0)

        for i, img_data in enumerate(processed_images):
            # æ·»åŠ å›¾ç‰‡æ ‡é¢˜
            doc.add_heading(f'å›¾ç‰‡ {i + 1} - æ¥æº: {img_data["source_file"]}', level=1)

            # æ·»åŠ å›¾ç‰‡
            try:
                # å°†å›¾ç‰‡æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
                temp_image_path = f"temp_image_{i}.png"
                with open(temp_image_path, 'wb') as f:
                    f.write(img_data['image_data'])

                # æ·»åŠ å›¾ç‰‡åˆ°æ–‡æ¡£
                doc.add_picture(temp_image_path, width=Inches(4))

                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_image_path)
            except Exception as e:
                doc.add_paragraph(f"å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")

            # æ·»åŠ ä¸Šä¸‹æ–‡
            doc.add_heading('ä¸Šä¸‹æ–‡', level=2)
            doc.add_paragraph(f"ä¸Šæ–‡: {img_data['context_before']}")
            doc.add_paragraph(f"ä¸‹æ–‡: {img_data['context_after']}")

            # æ·»åŠ æè¿°
            doc.add_heading('å›¾ç‰‡æè¿°', level=2)
            doc.add_paragraph(img_data['enhanced_description'])

            # æ·»åŠ åˆ†éš”çº¿
            doc.add_paragraph('\n' + '=' * 50 + '\n')

        doc.save(output_path)
        print(f"å›¾ç‰‡å’Œæè¿°å·²ä¿å­˜åˆ°: {output_path}")


class UnifiedImageManager:
    """ç»Ÿä¸€çš„å›¾ç‰‡ç®¡ç†å™¨ï¼Œç¡®ä¿MultiRAGå’ŒImageExtractorä½¿ç”¨ç›¸åŒçš„è·¯å¾„å’Œå‘½åè§„åˆ™"""
    
    def __init__(self, scene: str):
        self.scene = scene
        
        # æ ¹æ®åœºæ™¯è®¾ç½®è·¯å¾„
        if scene == "campus":
            self.docs_dir = str(CAMPUS_DOCS_DIR)
            self.output_dir = str(CAMPUS_IMAGES_PATH)
        else:
            self.docs_dir = str(PSYCHOLOGY_DOCS_DIR) 
            self.output_dir = str(PSYCHOLOGY_IMAGES_PATH)
            
        self.extractor = ImageExtractor(self.docs_dir, self.output_dir)
        self._ensure_directories()
    
    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        os.makedirs(self.output_dir, exist_ok=True)
    
    def process_images(self, incremental: bool = True, force_reprocess: bool = False) -> List[Dict]:
        """å¤„ç†å›¾ç‰‡å¹¶è¿”å›æ ¼å¼åŒ–æ•°æ®ï¼Œæ”¯æŒå¢é‡å¤„ç†"""
        # åŠ è½½å·²å¤„ç†çš„å›¾ç‰‡å“ˆå¸Œ
        processed_hashes = self._load_processed_hashes()
        
        # å¦‚æœéœ€è¦å¼ºåˆ¶é‡æ–°å¤„ç†ï¼Œæ¸…ç©ºå·²å¤„ç†å“ˆå¸Œ
        if force_reprocess:
            print(f"âš ï¸ å¼ºåˆ¶é‡æ–°å¤„ç†åœºæ™¯: {self.scene}")
            processed_hashes = set()
            
            # åˆ é™¤JSONæ–‡ä»¶ä»¥é‡æ–°å¼€å§‹
            json_path = self._get_scene_json_path()
            if os.path.exists(json_path):
                os.remove(json_path)
                print(f"å·²åˆ é™¤JSONæ–‡ä»¶: {json_path}")
        
        # ä½¿ç”¨ImageExtractorå¤„ç†å›¾ç‰‡
        new_images = self.extractor.process_all_documents(processed_hashes)
        return new_images
    
    def _load_processed_hashes(self) -> Set[str]:
        """ä»JSONæ–‡ä»¶åŠ è½½å·²å¤„ç†çš„å›¾ç‰‡å“ˆå¸Œ"""
        json_path = self._get_scene_json_path()
        
        if not os.path.exists(json_path):
            return set()
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                hashes = set(img['image_hash'] for img in data)
                print(f"ä»JSONæ–‡ä»¶åŠ è½½äº† {len(hashes)} ä¸ªå·²å¤„ç†çš„å›¾ç‰‡å“ˆå¸Œ")
                return hashes
        except Exception as e:
            print(f"åŠ è½½å·²å¤„ç†å“ˆå¸Œæ—¶å‡ºé”™: {e}")
            return set()
    
    def _get_scene_json_path(self) -> str:
        """è·å–åœºæ™¯å¯¹åº”çš„JSONæ–‡ä»¶è·¯å¾„"""
        if self.scene == "campus":
            return str(CAMPUS_EXTRACTED_IMAGES_JSON)
        elif self.scene == "psychology":
            return str(PSYCHOLOGY_EXTRACTED_IMAGES_JSON)
        else:
            return os.path.join(self.output_dir, f"{self.scene}_extracted_images.json")
    
    def reset_scene(self):
        """é‡ç½®åœºæ™¯å¤„ç†è¿›åº¦ï¼ˆåˆ é™¤JSONæ–‡ä»¶ï¼‰"""
        json_path = self._get_scene_json_path()
        if os.path.exists(json_path):
            os.remove(json_path)
            print(f"âœ… å·²é‡ç½®åœºæ™¯ {self.scene} çš„å¤„ç†è¿›åº¦")
        else:
            print(f"âš ï¸ åœºæ™¯ {self.scene} æ²¡æœ‰æ‰¾åˆ°å¯é‡ç½®çš„è¿›åº¦æ–‡ä»¶")


def main():
    """ä¸»å‡½æ•° - å¤„ç†å¤šä¸ªåœºæ™¯"""
    # # å¤„ç† campus åœºæ™¯
    # print("=" * 50)
    # print("å¼€å§‹å¤„ç† CAMPUS åœºæ™¯çš„Wordæ–‡æ¡£ä¸­çš„å›¾ç‰‡...")
    
    # campus_manager = UnifiedImageManager("campus")
    # processed_images_campus = campus_manager.process_images(incremental=True)
    
    # if processed_images_campus:
    #     print(f"\nCAMPUS åœºæ™¯æ€»å…±å¤„ç†äº† {len(processed_images_campus)} å¼ å›¾ç‰‡")
    # else:
    #     print("CAMPUS åœºæ™¯æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–°å›¾ç‰‡")
    
    # å¤„ç† psychology åœºæ™¯ï¼ˆå¼ºåˆ¶é‡æ–°å¤„ç†ï¼‰
    print("\n" + "=" * 50)
    print("å¼€å§‹å¤„ç† PSYCHOLOGY åœºæ™¯çš„Wordæ–‡æ¡£ä¸­çš„å›¾ç‰‡...")
    
    # é‡ç½®psychologyåœºæ™¯çš„å¤„ç†è¿›åº¦
    psychology_manager = UnifiedImageManager("psychology")
    psychology_manager.reset_scene()
    
    # å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰å›¾ç‰‡
    processed_images_psychology = psychology_manager.process_images(force_reprocess=True)
    
    if processed_images_psychology:
        print(f"\nPSYCHOLOGY åœºæ™¯æ€»å…±å¤„ç†äº† {len(processed_images_psychology)} å¼ å›¾ç‰‡")
    else:
        print("PSYCHOLOGY åœºæ™¯æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡")
    
    print("\n" + "=" * 50)
    print("æ‰€æœ‰åœºæ™¯çš„å›¾ç‰‡æå–å’Œå¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()